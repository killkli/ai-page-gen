import React, { useState, useEffect, useRef } from 'react';
import { speechService, SpeechRecognitionResult } from '../../services/speechService';

interface VoiceRecorderProps {
  targetText?: string; // æœŸæœ›å­¸ç”Ÿèªªå‡ºçš„æ–‡å­—
  onRecordingComplete: (result: {
    text: string;
    confidence: number;
    audioBlob?: Blob;
  }) => void;
  onRecordingStart?: () => void;
  onRecordingStop?: () => void;
  disabled?: boolean;
  language?: string;
  placeholder?: string;
}

const VoiceRecorder: React.FC<VoiceRecorderProps> = ({
  targetText,
  onRecordingComplete,
  onRecordingStart,
  onRecordingStop,
  disabled = false,
  language = 'en-US',
  placeholder = "Click to start recording..."
}) => {
  const [isRecording, setIsRecording] = useState(false);
  const [recognizedText, setRecognizedText] = useState('');
  const [confidence, setConfidence] = useState(0);
  const [isSupported, setIsSupported] = useState(true);
  const [error, setError] = useState<string | null>(null);
  const [audioLevel, setAudioLevel] = useState(0);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const animationRef = useRef<number>(0);
  
  // ä¿å­˜æœ€æ–°çš„èªéŸ³è­˜åˆ¥çµæœ
  const latestResultRef = useRef<{ text: string; confidence: number }>({ text: '', confidence: 0 });

  useEffect(() => {
    // æª¢æŸ¥ç€è¦½å™¨æ”¯æ´
    const support = speechService.getSupportStatus();
    setIsSupported(support.sttSupported);
    
    if (!support.sttSupported) {
      setError('Your browser does not support speech recognition');
    }

    return () => {
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
      }
    };
  }, []);

  // é–‹å§‹éŒ„éŸ³
  const startRecording = async () => {
    if (!isSupported || disabled) return;

    try {
      setError(null);
      setRecognizedText('');
      setConfidence(0);
      audioChunksRef.current = [];

      // è«‹æ±‚éº¥å…‹é¢¨æ¬Šé™ä¸¦é–‹å§‹éŒ„éŸ³
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      // è¨­ç½®åª’é«”éŒ„éŸ³å™¨
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.start();

      // é–‹å§‹èªéŸ³è­˜åˆ¥
      await speechService.startRecording(
        { lang: language, continuous: false, interimResults: true },
        (result: SpeechRecognitionResult) => {
          setRecognizedText(result.text);
          setConfidence(result.confidence);
          
          // åŒæ™‚ä¿å­˜åˆ°refä¸­
          latestResultRef.current = {
            text: result.text,
            confidence: result.confidence
          };
          
          console.log('VoiceRecorder: Speech recognition result:', result);
        },
        (error) => {
          console.error('Speech recognition error:', error);
          setError('Speech recognition failed. Please try again.');
          stopRecording();
        },
        () => {
          onRecordingStart?.();
          setIsRecording(true);
        },
        () => {
          setIsRecording(false);
          onRecordingStop?.();
          
          // èªéŸ³è­˜åˆ¥çµæŸæ™‚ç«‹å³è§¸ç™¼å›èª¿
          setTimeout(() => {
            // ä½¿ç”¨refä¸­ä¿å­˜çš„æœ€æ–°çµæœï¼Œè€Œä¸æ˜¯state
            const finalText = latestResultRef.current.text;
            const finalConfidence = latestResultRef.current.confidence;
            
            console.log('ğŸ”´ VoiceRecorder: Preparing callback with:', { finalText, finalConfidence });
            console.log('ğŸ”´ VoiceRecorder: About to call onRecordingComplete');
            
            // å…ˆç«‹å³è§¸ç™¼å›èª¿ï¼Œä¸ç­‰å¾…MediaRecorder
            console.log('ğŸ”´ VoiceRecorder: Triggering onRecordingComplete NOW');
            onRecordingComplete({
              text: finalText,
              confidence: finalConfidence,
              audioBlob: undefined // å…ˆä¸åŒ…å«éŸ³é »ï¼Œç¢ºä¿å›èª¿æ­£å¸¸å·¥ä½œ
            });
            
            // ç„¶å¾Œå˜—è©¦è™•ç†éŸ³é »ï¼ˆå¦‚æœéœ€è¦çš„è©±ï¼‰
            if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
              mediaRecorderRef.current.stop();
              
              // å¦‚æœéŸ³é »è™•ç†æˆåŠŸï¼Œå¯ä»¥å†æ¬¡è§¸ç™¼å›èª¿åŒ…å«éŸ³é »
              mediaRecorderRef.current.onstop = () => {
                const audioBlob = audioChunksRef.current.length > 0 ? 
                  new Blob(audioChunksRef.current, { type: 'audio/wav' }) : undefined;
                
                if (audioBlob) {
                  console.log('VoiceRecorder: Updating with audio blob');
                  onRecordingComplete({
                    text: finalText,
                    confidence: finalConfidence,
                    audioBlob: audioBlob
                  });
                }
              };
            }
          }, 200);
        }
      );

      // é–‹å§‹éŸ³é »å¯è¦–åŒ–
      startAudioVisualization(stream);

    } catch (error) {
      console.error('Failed to start recording:', error);
      setError('Failed to access microphone. Please check permissions.');
    }
  };

  // åœæ­¢éŒ„éŸ³ (ä¸»è¦ç”±èªéŸ³è­˜åˆ¥æœå‹™çš„onEndå›èª¿è™•ç†)
  const stopRecording = () => {
    if (!isRecording) return;

    speechService.stopRecording();
    
    setAudioLevel(0);
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current);
    }
  };

  // éŸ³é »å¯è¦–åŒ–
  const startAudioVisualization = (stream: MediaStream) => {
    const audioContext = new AudioContext();
    const analyser = audioContext.createAnalyser();
    const microphone = audioContext.createMediaStreamSource(stream);
    microphone.connect(analyser);

    analyser.fftSize = 256;
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    const updateAudioLevel = () => {
      if (!isRecording) return;

      analyser.getByteFrequencyData(dataArray);
      const average = dataArray.reduce((acc, val) => acc + val, 0) / bufferLength;
      setAudioLevel(average / 255);

      animationRef.current = requestAnimationFrame(updateAudioLevel);
    };

    updateAudioLevel();
  };

  // æ¸²æŸ“éŒ„éŸ³æŒ‰éˆ•
  const renderRecordButton = () => {
    const baseClasses = "relative flex items-center justify-center w-16 h-16 rounded-full transition-all duration-200 focus:outline-none focus:ring-4 focus:ring-offset-2";
    
    if (disabled) {
      return (
        <button
          className={`${baseClasses} bg-gray-300 cursor-not-allowed`}
          disabled
        >
          <svg className="w-6 h-6 text-gray-500" fill="currentColor" viewBox="0 0 24 24">
            <path d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.48 6-3.3 6-6.72h-1.7z"/>
          </svg>
        </button>
      );
    }

    if (isRecording) {
      return (
        <button
          onClick={stopRecording}
          className={`${baseClasses} bg-red-500 hover:bg-red-600 text-white focus:ring-red-300 animate-pulse`}
          style={{
            transform: `scale(${1 + audioLevel * 0.3})`,
          }}
        >
          <div className="w-4 h-4 bg-white rounded-sm"></div>
          
          {/* éŸ³é »æ³¢å½¢ç’° */}
          <div 
            className="absolute inset-0 rounded-full border-4 border-red-300"
            style={{
              transform: `scale(${1.2 + audioLevel * 0.5})`,
              opacity: audioLevel * 0.7
            }}
          ></div>
        </button>
      );
    }

    return (
      <button
        onClick={startRecording}
        className={`${baseClasses} bg-blue-500 hover:bg-blue-600 text-white focus:ring-blue-300`}
      >
        <svg className="w-6 h-6" fill="currentColor" viewBox="0 0 24 24">
          <path d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.48 6-3.3 6-6.72h-1.7z"/>
        </svg>
      </button>
    );
  };

  if (!isSupported) {
    return (
      <div className="flex flex-col items-center space-y-2 p-4 bg-red-50 rounded-lg border border-red-200">
        <div className="text-red-600 text-sm font-medium">
          Speech recognition not supported
        </div>
        <div className="text-red-500 text-xs text-center">
          Please use Chrome, Edge, or Safari for voice recording
        </div>
      </div>
    );
  }

  return (
    <div className="flex flex-col items-center space-y-4">
      {/* éŒ„éŸ³æŒ‰éˆ• */}
      <div className="flex flex-col items-center space-y-2">
        {renderRecordButton()}
        
        <div className="text-sm text-gray-600 text-center">
          {isRecording ? (
            <span className="text-red-600 font-medium">Recording...</span>
          ) : (
            placeholder
          )}
        </div>
      </div>

      {/* è­˜åˆ¥çµæœé¡¯ç¤º */}
      {recognizedText && (
        <div className="w-full max-w-md">
          <div className="bg-gray-50 rounded-lg p-3 border">
            <div className="text-sm font-medium text-gray-700 mb-1">
              You said:
            </div>
            <div className="text-gray-900">
              "{recognizedText}"
            </div>
            {confidence > 0 && (
              <div className="mt-2 flex items-center space-x-2">
                <span className="text-xs text-gray-500">Confidence:</span>
                <div className="flex-1 bg-gray-200 rounded-full h-2">
                  <div 
                    className={`h-2 rounded-full transition-all duration-300 ${
                      confidence > 0.8 ? 'bg-green-500' : 
                      confidence > 0.6 ? 'bg-yellow-500' : 'bg-red-500'
                    }`}
                    style={{ width: `${confidence * 100}%` }}
                  ></div>
                </div>
                <span className="text-xs text-gray-500">
                  {Math.round(confidence * 100)}%
                </span>
              </div>
            )}
          </div>
        </div>
      )}

      {/* éŒ¯èª¤è¨Šæ¯ */}
      {error && (
        <div className="text-red-600 text-sm bg-red-50 px-3 py-2 rounded-lg border border-red-200">
          {error}
        </div>
      )}

      {/* ç›®æ¨™æ–‡å­—æ¯”è¼ƒ (å¦‚æœæä¾›) */}
      {targetText && recognizedText && (
        <div className="w-full max-w-md text-xs text-gray-500 bg-blue-50 p-3 rounded-lg border border-blue-200">
          <div className="font-medium mb-1">Expected:</div>
          <div className="text-blue-700">"{targetText}"</div>
        </div>
      )}
    </div>
  );
};

export default VoiceRecorder;
